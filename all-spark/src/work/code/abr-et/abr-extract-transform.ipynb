{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@62e8034e\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://7ccdbe56bea6:4040)\" target=\"new_tab\">Spark UI: local-1536218700155</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark local-1536218700155: Some(http://7ccdbe56bea6:4040)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.Column\n",
    "import org.apache.spark.sql.functions.{concat, lit,concat_ws}\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Spark SQL basic example\")\n",
    "  .config(\"spark.some.config.option\", \"some-value\")\n",
    "  .getOrCreate()\n",
    "\n",
    "// For implicit conversions like converting RDDs to DataFrames\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asArrayDelimited: (c: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def asArrayDelimited(c: Column) = concat(concat_ws(\"|\", c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfCompanyNames = [data: struct<value: string>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<value: string>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfCompanyNames = spark.read.json(\"/abr/vertices/company-names/*.txt\")\n",
    "\n",
    "dfCompanyNames\n",
    "    .select(\"id\",\"data.value\",\"meta.graphs\")\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/company-names/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [data: struct<value: string>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<value: string>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfBusinessNames = spark.read.json(\"/abr/vertices/business-names/*.txt\")\n",
    "\n",
    "dfBusinessNames\n",
    "    .select(\"id\",\"data.value\",\"meta.graphs\")\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/business-names/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfABN = [data: struct<abn: string, abnStatus: string ... 6 more fields>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<abn: string, abnStatus: string ... 6 more fields>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfABN = spark.read.json(\"/abr/vertices/{abn-abr,asic-abn-without-an-abr}/*.txt\")\n",
    "\n",
    "dfABN\n",
    "    .select(\"id\",\n",
    "             \"data.abn\",\n",
    "             \"data.abnStatus\",\n",
    "             \"data.entityType\",\n",
    "             \"data.entityTypeDescription\",\n",
    "             \"data.gstStatus\",\n",
    "             \"data.gstStatusFrom\",\n",
    "             \"data.value\",\n",
    "             \"meta.graphs\")\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/abn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfACN: Unit = ()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val dfACN = spark.read.json(\"/abr/vertices/acn-abr-and-company-names/*.txt\")\n",
    "\n",
    "dfACN\n",
    "    .select(\"id\",\"data.value\",\"meta.graphs\")\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/acn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfLegalEntity = [data: struct<address: struct<postCode: string, state: string>, familyName: string ... 3 more fields>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<address: struct<postCode: string, state: string>, familyName: string ... 3 more fields>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfLegalEntity = spark.read.json(\"/abr/vertices/legal-entity/*.txt\")\n",
    "\n",
    "dfLegalEntity\n",
    "    .select(\"id\",\n",
    "            \"data.address.postCode\",\n",
    "            \"data.address.state\",\n",
    "            \"data.familyName\",\n",
    "            \"data.givenNames\",\n",
    "            \"data.title\",\n",
    "            \"data.type\",\n",
    "            \"meta.graphs\"\n",
    "           )\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .withColumn(\"givenNames\",asArrayDelimited($\"givenNames\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/legal-entity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfMainEntity = [data: struct<address: struct<postCode: string, state: string>, nonIndividualName: string ... 1 more field>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<address: struct<postCode: string, state: string>, nonIndividualName: string ... 1 more field>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfMainEntity = spark.read.json(\"/abr/vertices/main-entity/*.txt\")\n",
    "\n",
    "dfMainEntity\n",
    "    .select(\"id\",\n",
    "            \"data.address.postCode\",\n",
    "            \"data.address.state\",\n",
    "            \"data.nonIndividualName\",\n",
    "            \"data.type\",\n",
    "            \"meta.graphs\"\n",
    "           )\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/main-entity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfOtherEntity = [data: struct<nonIndividualName: string, type: string>, id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[data: struct<nonIndividualName: string, type: string>, id: string ... 1 more field]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfOtherEntity = spark.read.json(\"/abr/vertices/other-entity/*.txt\")\n",
    "\n",
    "dfOtherEntity\n",
    "    .select(\"id\",\n",
    "            \"data.nonIndividualName\",\n",
    "            \"data.type\",\n",
    "            \"meta.graphs\"\n",
    "           )\n",
    "    .withColumn(\"graphs\",asArrayDelimited($\"graphs\"))\n",
    "    .write.format(\"csv\").save(\"/abr/vertices.csv/main-entity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- nonIndividualName: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- graphs: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfOtherEntity.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
